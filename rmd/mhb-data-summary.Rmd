---
title: "Maine Healthy Beaches: Data Exploration to Support Threshold Justification"
author: "Jeffrey D Walker, PhD"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
  html_document: 
    css: styles.css
    number_sections: yes
    toc: yes
---

```{r libraries, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(stringr)
library(lubridate)
library(ggplot2)
theme_set(theme_bw())
library(gridExtra)
library(knitr)
library(readxl)

DATA_DIR <- '~/Dropbox/Work/mhb/data/'

opts_chunk$set(echo=FALSE, message=FALSE)
```

```{r load-data, cache=TRUE, results='hide'}
sites <- read.csv(file=file.path(DATA_DIR, 'locations.csv'), stringsAsFactors=FALSE) %>%
  select(BEACH_ID=EGAD.Site.Sequence.., BEACH_NAME=CURRENT_SITE_NAME,
         SITE_ID=EGAD.Sample.Point.Sequence.., SITE_NAME=CURRENT_SAMPLE_POINT_NAME,
         LATITUDE, LONGITUDE, UTM_X=UTM.X, UTM_Y=UTM.Y)
glimpse(sites)

beaches <- read.csv(file=file.path(DATA_DIR, 'beaches.csv'), stringsAsFactors=FALSE) %>%
  select(BEACH_ID=EGAD_SEQ, BEACH_NAME=CURRENT_SITE_NAME,
         LATITUDE, LONGITUDE, UTM_X, UTM_Y)
glimpse(beaches)

data1 <- read_excel(file.path(DATA_DIR, "../MHB Data Extract/MHB data extract.xlsx"),
                    col_types=c("numeric", "text", "text", "text", "text", "date",
                                "text", "text", "text", "text", "text", "numeric",
                                "text", "text", "numeric", "numeric", "text", "numeric",
                                "text", "text", "text", "text", "text", "text",
                                "numeric", "text", "text", "text", "text"))
names(data1) <- str_replace_all(names(data1), '[ ]', '_')
data1 <- rename(data1, SITE_LATITUDE_UTM=`SITE_LATITUDE_(UTM)`, SITE_LONGITUDE_UTM=`SITE_LONGITUDE_(UTM)`)
data1 <- mutate_each(data1, funs(as.numeric), SITE_LATITUDE_UTM, SITE_LONGITUDE_UTM)

data2 <- read_excel(file.path(DATA_DIR, "../MHB Data Extract/MHB_2014.xlsx"),
                    col_types=c("numeric", "text", "text", "text", "text", "date",
                                "text", "text", "text", "text", "text", "numeric",
                                "text", "text", "numeric", "numeric", "text", "numeric",
                                "text", "text", "text", "text", "text", "text",
                                "numeric", "text", "text", "text", "text"))
names(data2) <- str_replace_all(names(data2), '[ ]', '_')
data2 <- rename(data2,
                SITE_SEQUENCE_NUMBER=SITE_NUMBER,
                SAMPLE_SEQUENCE_NUMBER=SAMPLE_NUMBER,
                SITE_LATITUDE_UTM=`SITE_LATITUDE_(UTM)`, SITE_LONGITUDE_UTM=`SITE_LONGITUDE_(UTM)`)
data2 <- mutate_each(data2, funs(as.numeric), SITE_LATITUDE_UTM, SITE_LONGITUDE_UTM)

df <- rbind(data1, data2)

df <- rename(df,
             BEACH_ID=SITE_SEQUENCE_NUMBER,
             BEACH_NAME=SITE_NAME,
             SITE_NAME=SAMPLE_POINT_NAME,
             SAMPLE_DATETIME=SAMPLE_DATE)

df <- mutate_each(df, funs(factor),
                  SAMPLE_TYPE, SAMPLE_TYPE_QUALIFIER, COLLECTION_METHOD,
                  PARAMETER_NAME, PARAMETER_UNITS, TEST_METHOD, TEST_METHOD_DESCRIPTION,
                  RESULT_TYPE, ANALYSIS_LAB)

df <- mutate(df, 
             BEACH_NAME=str_trim(BEACH_NAME),
             SITE_NAME=str_trim(SITE_NAME),
             SAMPLE_DATE=floor_date(SAMPLE_DATETIME, unit="day"),
             YEAR=year(SAMPLE_DATE),
             MONTH=month(SAMPLE_DATE))

df <- filter(df, !is.na(CONCENTRATION))

ent <- filter(df, PARAMETER_NAME=='ENTEROCOCCI') %>%
  select(TOWN, BEACH_ID, BEACH_NAME, SITE_NAME, SAMPLE_DATETIME, SAMPLE_DATE, YEAR, MONTH,
         CONCENTRATION, CONCENTRATION_QUALIFIER, PARAMETER_UNITS, QUANITATION_LIMIT, 
         METHOD_DETECTION_LIMIT, DILUTION_FACTOR, TEST_METHOD, SAMPLE_COMMENTS, ANALYSIS_LAB)
```

```{r check-sites, results='hide'}
ent_sites <- select(ent, TOWN, BEACH_ID, BEACH_NAME, SITE_NAME) %>%  
  unique
glimpse(ent_sites)

stopifnot(all(ent_sites$SITE_NAME %in% sites$SITE_NAME))

# list of duplicate SITE_NAMEs
# some have new beaches, which are similar to the primary beach in the sites table
group_by(ent_sites, TOWN, SITE_NAME) %>%
  mutate(N=n()) %>%
  ungroup %>%
  filter(N>1) %>%
  arrange(SITE_NAME) %>%
  left_join(select(sites, SITE_NAME, BEACH_ID, BEACH_NAME), by="SITE_NAME")

# replace BEACH_ID and BEACH_NAME in ent with those in sites
ent <- select(ent, -BEACH_ID, -BEACH_NAME) %>%
  left_join(select(sites, SITE_NAME, BEACH_ID, BEACH_NAME))
ent_sites <- select(ent, TOWN, BEACH_ID, BEACH_NAME, SITE_NAME) %>%  
  unique
stopifnot(sum(duplicated(ent_sites$SITE_NAME)) == 0)

# check missing values by column
sapply(ent, function (x) { sum(is.na(x)) })
```

```{r define-limits, results='hide'}
ent <- mutate(ent,
              GT_70=CONCENTRATION > 70,
              GT_104=CONCENTRATION > 104,
              CLASS=ordered(GT_70+GT_104, levels=c(0, 1, 2), labels=c('<=70', '70-104', '>104')))
glimpse(ent)

scale_class_fill <- scale_fill_manual('', values=c('<=70'='grey50', '70-104'='deepskyblue', '>104'='orangered'))
scale_class_color <- scale_color_manual('', values=c('<=70'='grey50', '70-104'='deepskyblue', '>104'='orangered'))

ent_limits <- data.frame(CONCENTRATION=c(70, 104), LABEL=ordered(c('70', '104')))
scale_limits_color <- scale_color_manual('', values=c('70'='deepskyblue', '104'='orangered'))
```

```{r ent-counts}
ent <- group_by(ent, TOWN, BEACH_NAME, SITE_NAME) %>%
  mutate(N_SITE=n()) %>%
  group_by(TOWN, BEACH_NAME) %>%
  mutate(N_BEACH=n()) %>%
  group_by(TOWN) %>%
  mutate(N_TOWN=n()) %>%
  ungroup
```


```{r plot-functions}
log_breaks <- function(x, y) {
  # log breaks
  as.vector(outer(x, y, '*'))
}
log_labels <- function(x, y) {
  # labels for log scales with gaps
  x_na <- seq(1, 9)
  x_na[which(!(x_na %in% x))] <- NA
  x <- log_breaks(x_na, y)
  x <- as.character(x)
  x <- ifelse(is.na(x), "", x)
  x
}
log_x <- scale_x_log10(breaks=log_breaks(seq(1, 9), 10^seq(-3, 5)),
                       labels=log_labels(c(1, 5), 10^seq(-3, 5)))
log_y <- scale_y_log10(breaks=log_breaks(seq(1, 9), 10^seq(-3, 5)),
                       labels=log_labels(c(1, 5), 10^seq(-3, 5)))
```


# Distribution of Enterococcus Concentrations

## All Samples

This section summarizes the entire population of all enterococcus samples.

This figure shows the histogram of all samples on a log-scale. The vertical lines show the 70 and 104 limits.

The distribution is uni-modal, the large change at 10 MPN/100mL is due to the detection limits.

```{r plot-histogram}
ent %>%
  ggplot() +
  geom_histogram(aes(CONCENTRATION), binwidth=0.3) +
  geom_vline(aes(xintercept=CONCENTRATION, color=LABEL), data=ent_limits, show_guide=TRUE) +
  scale_limits_color +
  scale_y_continuous(labels=scales::comma) +
  log_x +
  labs(x="ENT", y="# Samples",
       title="Distribution of All Samples")
```

This figure shows the same data, but on a linear scale and only including samples with ENT < 200 to focus on the lower range.

```{r plot-histogram-200}
ent %>%
  filter(CONCENTRATION < 200) %>%
  ggplot() +
  geom_histogram(aes(CONCENTRATION), binwidth=10) +
  geom_vline(aes(xintercept=CONCENTRATION, color=LABEL), data=ent_limits, show_guide=TRUE) +
  scale_limits_color +
  scale_y_continuous(labels=scales::comma) +
  labs(x="ENT (MPN/100mL)", y="# Samples",
       title="Distribution of All Samples with ENT < 200")
```

**Question**: What fraction of all samples are between 70 and 104?

**Answer**: `r scales::percent(prop.table(table(ent$CLASS))['70-104'])`

This table shows the fraction of samples <70, between 70-104, and >104.

```{r prop-class}
ent %>% 
  select(CLASS) %>% 
  table() %>%
  prop.table() %>%
  as.data.frame %>%
  kable(col.names=c('Range', 'Fraction'), digits=3)
```


**Question**: If a sample is greater than 70 MPN/100mL, what is the probability it is also > 104?

**Answer**: `r scales::percent(prop.table(table(filter(ent, GT_70)$CLASS))['>104'])`

This table shows the fraction of samples between 70-104 and >104 based only on samples with concentrations <70.

```{r prop-class-gt70}
ent %>% 
  filter(GT_70) %>%
  droplevels %>% 
  select(CLASS) %>% 
  table() %>%
  prop.table() %>%
  as.data.frame %>%
  kable(col.names=c('Range', 'Fraction'), digits=3)
```

**Question**: If the threshold were lowered from 104 to 70, how many more days would be exceedences?

**Answer**: There were `r nrow(filter(ent, GT_104))` days exceeding 104, and `r (nrow(filter(ent, GT_70))-nrow(filter(ent, GT_104)))` days between 70 and 104. So there would be `r scales::percent((nrow(filter(ent, GT_70))-nrow(filter(ent, GT_104)))/nrow(filter(ent, GT_104)))` more exceedence days.

## By Beach

In this section, the data are grouped by beach and thus may include more than one sampling site. Beaches with fewer than 20 samples in total are excluded, which include:

```{r tbl-beaches-excluded}
group_by(ent, TOWN, BEACH_NAME) %>% 
  summarise(N_SAMPLE=n()) %>% 
  ungroup %>% 
  arrange(N_SAMPLE) %>%
  filter(N_SAMPLE<20) %>%
  kable
```


This figure shows the total number of samples in each category (<70, 70-104, >104), ordered by the total number of samples.

```{r plot-count-beach, fig.width=10, fig.height=10}
ent %>%
  filter(N_BEACH >= 20) %>%
  arrange(N_BEACH) %>%
  mutate(BEACH_NAME=ordered(BEACH_NAME, levels=unique(BEACH_NAME))) %>%
  group_by(BEACH_NAME, CLASS) %>%
  summarise(N=n()) %>%
  ungroup %>%
  spread(CLASS, N, fill=0) %>%
  gather(CLASS, N, -BEACH_NAME) %>%
  mutate(CLASS=ordered(CLASS, levels=rev(levels(ent$CLASS)))) %>%
  mutate(FRAC=N/sum(N)) %>%
  ungroup %>%
  arrange(desc(CLASS)) %>%
  ggplot(aes(BEACH_NAME, N, fill=CLASS)) +
  geom_bar(stat='identity', position='stack') +
  scale_class_fill +
  labs(y="Number of Samples", x="Beach",
       title="Number of Samples by Beach and Category") +
  coord_flip() +
  theme(axis.text.y=element_text(size=6))
```

This figure shows the same data, but instead of the number of samples, it shows the fraction of samples in each category by beach ordered by the fraction >104 (dirtiest beaches at the top, cleanest at the bottom). 

```{r plot-count-beach-pct, fig.width=10, fig.height=10}
ent %>%
  filter(N_BEACH >= 20) %>%
  group_by(BEACH_NAME, CLASS) %>%
  summarise(N=n()) %>%
  mutate(FRAC=N/sum(N)) %>%
  ungroup %>%
  select(-N) %>%
  spread(CLASS, FRAC, fill=0) %>%
  arrange(`>104`) %>%
  mutate(BEACH_NAME=ordered(BEACH_NAME, levels=unique(BEACH_NAME))) %>%
  gather(CLASS, FRAC, -BEACH_NAME) %>%
  mutate(CLASS=ordered(CLASS, levels=rev(levels(ent$CLASS)))) %>%
  arrange(desc(CLASS)) %>%
  ggplot(aes(BEACH_NAME, FRAC, fill=CLASS)) +
  geom_bar(stat='identity', position='stack') +
  scale_class_fill +
  scale_y_continuous(labels=scales::percent) +
  labs(y="% of Samples", x="Beach",
       title="Fraction of Samples by Beach and Category") +
  coord_flip() +
  theme(axis.text.y=element_text(size=6))
```

This figure shows only the fraction of total samples between 70-104 (the blue bars of the previous figure) and ordered from highest to lowest. 

```{r plot-beach-count-pct-70-104, fig.width=10, fig.height=10}
ent %>%
  filter(N_BEACH >= 20) %>%
  group_by(BEACH_NAME, CLASS) %>%
  summarise(N=n()) %>%
  mutate(FRAC=N/sum(N)) %>%
  ungroup %>%
  select(-N) %>%
  spread(CLASS, FRAC, fill=0) %>%
  arrange(`70-104`) %>%
  mutate(BEACH_NAME=ordered(BEACH_NAME, levels=unique(BEACH_NAME))) %>%
  gather(CLASS, FRAC, -BEACH_NAME) %>%
  mutate(CLASS=ordered(CLASS, levels=rev(levels(ent$CLASS)))) %>%
  arrange(desc(CLASS)) %>%
  filter(CLASS=="70-104") %>%
  ggplot(aes(BEACH_NAME, FRAC, fill=CLASS)) +
  geom_bar(stat='identity', position='stack') +
  scale_class_fill +
  scale_y_continuous(labels=scales::percent, breaks=seq(0, 1, by=0.01)) +
  labs(y="% of Samples", x="Beach",
       title="Fraction of Samples between 70-104 by Beach and Category") +
  coord_flip() +
  theme(axis.text.y=element_text(size=6))
```

This figure shows the cumulative distribution of % samples for each category across beaches. It shows, for example, that 50% of the beaches have 80.7% or less of samples <70 (dotted gray line), and that 90% of beaches have 9.4% or less of samples between 70-104 (dotted blue line).

```{r plot-beaches-cdf, fig.width=8, fig.height=6}
ent %>%
  filter(N_BEACH >= 20) %>%
  group_by(BEACH_NAME, CLASS) %>%
  summarise(N=n()) %>%
  mutate(FRAC=N/sum(N)) %>%
  ungroup %>%
  arrange(CLASS, FRAC) %>%
  group_by(CLASS) %>%
  mutate(INDEX=row_number()/n()) %>%
  ggplot(aes(INDEX, FRAC, color=CLASS)) +
  geom_point() +
  geom_line() +
  geom_segment(x=0, xend=0.5, y=0.8068, yend=0.8068, color='grey50', linetype='dotted') +
  geom_segment(x=0.5, xend=0.5, y=0, yend=0.8068, color='grey50', linetype='dotted') +
  geom_segment(x=0, xend=0.9, y=0.09375, yend=0.09375, color='deepskyblue', linetype='dotted') +
  geom_segment(x=0.9, xend=0.9, y=0, yend=0.09375, color='deepskyblue', linetype='dotted') +
  scale_class_color +
  scale_x_continuous(labels=scales::percent, breaks=seq(0, 1, 0.1)) +
  scale_y_continuous(labels=scales::percent, breaks=seq(0, 1, 0.1)) +
  labs(x="% of Beaches", y="% of Samples",
       title="Cumulative Distribution of Fraction Samples by Beach and Category")
```

This figure shows the same data, but separates each category into separate panels with different y-axis scales.

```{r plot-beaches-cdf-facet, fig.width=10, fig.height=4}
ent %>%
  filter(N_BEACH >= 20) %>%
  group_by(BEACH_NAME, CLASS) %>%
  summarise(N=n()) %>%
  mutate(FRAC=N/sum(N)) %>%
  ungroup %>%
  # filter(CLASS=='70-104') %>%
  arrange(CLASS, FRAC) %>%
  group_by(CLASS) %>%
  mutate(INDEX=row_number()/n()) %>%
  ggplot(aes(INDEX, FRAC, color=CLASS)) +
  geom_point() +
  geom_line() +
  scale_class_color +
  scale_x_continuous(labels=scales::percent, breaks=seq(0, 1, 0.1)) +
  scale_y_continuous(labels=scales::percent) +
  labs(x="% of Beaches", y="% of Samples",
       title="Cumulative Distribution of Fraction Samples by Beach and Category with Panels") +
  facet_wrap(~CLASS, scales='free_y') +
  theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))
```


## By Site

In this section, the data are grouped by site instead of beach. Sites with fewer than 10 samples in total are excluded, which include:

```{r tbl-sites-excluded}
group_by(ent, TOWN, BEACH_NAME, SITE_NAME) %>% 
  summarise(N_SAMPLE=n()) %>% 
  ungroup %>% 
  arrange(N_SAMPLE) %>%
  filter(N_SAMPLE<10) %>%
  kable
```


This figure shows the total number of samples in each category (<70, 70-104, >104), ordered by the total number of samples.

```{r plot-count-site, fig.width=10, fig.height=12}
ent %>%
  filter(N_SITE >= 10) %>%
  group_by(SITE_NAME, CLASS) %>%
  summarise(N=n()) %>%
  ungroup %>%
  spread(CLASS, N, fill=0) %>%
  gather(CLASS, N, -SITE_NAME) %>%
  mutate(CLASS=ordered(CLASS, levels=rev(levels(ent$CLASS)))) %>%
  mutate(FRAC=N/sum(N)) %>%
  group_by(SITE_NAME) %>%
  mutate(N_SITE=sum(N)) %>%
  ungroup %>%
  filter(N_SITE >= 10) %>%
  arrange(N_SITE) %>%
  mutate(SITE_NAME=ordered(SITE_NAME, levels=unique(SITE_NAME))) %>%
  arrange(desc(CLASS)) %>%
  ggplot(aes(SITE_NAME, N, fill=CLASS)) +
  geom_bar(stat='identity', position='stack') +
  scale_class_fill +
  labs(y="Number of Samples", x="Beach",
       title="Number of Samples by Site and Category") +
  coord_flip() +
  theme(axis.text.y=element_text(size=6))
```

This figure shows the same data, but instead of the number of samples, it shows the fraction of samples in each category by beach ordered by the fraction >104 (dirtiest beaches at the top, cleanest at the bottom). 

```{r plot-count-site-pct, fig.width=10, fig.height=10}
ent %>%
  filter(N_SITE >= 10) %>%
  group_by(SITE_NAME, CLASS) %>%
  summarise(N=n()) %>%
  mutate(FRAC=N/sum(N)) %>%
  ungroup %>%
  group_by(SITE_NAME) %>%
  mutate(N_SITE=sum(N)) %>%
  filter(N_SITE > 10) %>%
  select(-N, -N_SITE) %>%
  spread(CLASS, FRAC, fill=0) %>%
  arrange(`>104`) %>%
  mutate(SITE_NAME=ordered(SITE_NAME, levels=unique(SITE_NAME))) %>%
  gather(CLASS, FRAC, -SITE_NAME) %>%
  mutate(CLASS=ordered(CLASS, levels=rev(levels(ent$CLASS)))) %>%
  arrange(desc(CLASS)) %>%
  ggplot(aes(SITE_NAME, FRAC, fill=CLASS)) +
  geom_bar(stat='identity', position='stack') +
  scale_class_fill +
  scale_y_continuous(labels=scales::percent) +
  labs(y="% of Samples", x="Site",
       title="Fraction of Samples by Beach and Category") +
  coord_flip() +
  theme(axis.text.y=element_text(size=6))
```

This figure shows only the fraction of total samples between 70-104 (the blue bars of the previous figure) and ordered from highest to lowest. 

```{r plot-site-count-pct-70-104, fig.width=10, fig.height=10}
ent %>%
  filter(N_SITE >= 10) %>%
  group_by(SITE_NAME, CLASS) %>%
  summarise(N=n()) %>%
  mutate(FRAC=N/sum(N)) %>%
  ungroup %>%
  select(-N) %>%
  spread(CLASS, FRAC, fill=0) %>%
  arrange(`70-104`) %>%
  mutate(SITE_NAME=ordered(SITE_NAME, levels=unique(SITE_NAME))) %>%
  gather(CLASS, FRAC, -SITE_NAME) %>%
  mutate(CLASS=ordered(CLASS, levels=rev(levels(ent$CLASS)))) %>%
  arrange(desc(CLASS)) %>%
  filter(CLASS=="70-104") %>%
  ggplot(aes(SITE_NAME, FRAC, fill=CLASS)) +
  geom_bar(stat='identity', position='stack') +
  scale_class_fill +
  scale_y_continuous(labels=scales::percent, breaks=seq(0, 1, by=0.01)) +
  labs(y="% of Samples", x="Site",
       title="Fraction of Samples between 70-104 by Site and Category") +
  coord_flip() +
  theme(axis.text.y=element_text(size=6))
```

This figure shows the cumulative distribution of % samples for each category across beaches. It shows, for example, that 50% of the beaches have 81.2% or less of samples <70 (dotted gray line), and that 90% of beaches have 9.7% or less of samples between 70-104 (dotted blue line).

```{r plot-sites-cdf, fig.width=8, fig.height=6}
ent %>%
  filter(N_SITE >= 10) %>%
  group_by(SITE_NAME, CLASS) %>%
  summarise(N=n()) %>%
  mutate(FRAC=N/sum(N)) %>%
  ungroup %>%
  # filter(CLASS=='70-104') %>%
  arrange(CLASS, FRAC) %>%
  group_by(CLASS) %>%
  mutate(INDEX=row_number()/n()) %>%
  ggplot(aes(INDEX, FRAC, color=CLASS)) +
  geom_point() +
  geom_line() +
  geom_segment(x=0, xend=0.5, y=0.8132, yend=0.8132, color='grey50', linetype='dotted') +
  geom_segment(x=0.5, xend=0.5, y=0, yend=0.8132, color='grey50', linetype='dotted') +
  geom_segment(x=0, xend=0.9, y=0.09709, yend=0.09709, color='deepskyblue', linetype='dotted') +
  geom_segment(x=0.9, xend=0.9, y=0, yend=0.09709, color='deepskyblue', linetype='dotted') +
  scale_class_color +
  scale_x_continuous(labels=scales::percent, breaks=seq(0, 1, 0.1)) +
  scale_y_continuous(labels=scales::percent, breaks=seq(0, 1, 0.1)) +
  labs(x="% of Sites", y="% of Samples",
       title="Cumulative Distribution of Fraction Samples by Site and Category")
```

This figure shows the same data, but separates each category into separate panels with different y-axis scales.

```{r plot-sites-cdf-facet, fig.width=10, fig.height=4}
ent %>%
  group_by(SITE_NAME, CLASS) %>%
  summarise(N=n()) %>%
  mutate(FRAC=N/sum(N)) %>%
  ungroup %>%
  arrange(CLASS, FRAC) %>%
  group_by(CLASS) %>%
  mutate(INDEX=row_number()/n()) %>%
  ggplot(aes(INDEX, FRAC, color=CLASS)) +
  geom_point() +
  geom_line() +
  scale_class_color +
  scale_x_continuous(labels=scales::percent, breaks=seq(0, 1, 0.1)) +
  scale_y_continuous(labels=scales::percent) +
  labs(x="% of Sites", y="% of Samples",
       title="Cumulative Distribution of Fraction Samples by Site and Category with Panels") +
  facet_wrap(~CLASS, scales='free_y') +
  theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))
```


# Sampling Frequency and Resampling

This section looks at the frequency of sampling. Are most sites weekly? How often are resamples collected?

```{r ent-dt}
ent <- arrange(ent, SITE_NAME, SAMPLE_DATE) %>%
  group_by(SITE_NAME) %>%
  mutate(DT=as.numeric(difftime(SAMPLE_DATETIME, lag(SAMPLE_DATETIME), units="days")))
```

This figure shows a histogram of the number of days between samples based on the entire dataset and excluding samples taken more than 35 days from the previous sample. There are obvious peaks at 7, 14, 21, and 28 days corresponding to weekly, biweekly, triweekly, and quatro(?)weekly sampling schedules. There are also a fair number of samples collected 1 day or less from the previous sample.

```{r plot-dt-histogram}
ent %>%
  filter(DT<35) %>%
  ggplot(aes(DT)) +
  geom_histogram(binwidth=1, fill='grey50', color='white') +
  scale_x_continuous(breaks=seq(0, 50, 7)) +
  labs(x="Days between Samples", y="# of Samples",
       title="Histogram of # Days between Samples")
```

## Samples Collected within 1.5 Days of Previous Sample

This section focuses on samples collected within 1.5 days of the previous sample.

This figure shows the distribution of time between samples and distinguishing between samples concentrations <70, 70-104, and >104. The majority of these daily consecutive samples were below both the 70 and 104 thresholds.

```{r plot-dt-hist-1-day}
ent %>%
  filter(DT<1.5) %>%
  ggplot(aes(DT, fill=CLASS)) +
  geom_histogram(binwidth=1/24, color='white') +
  scale_class_fill +
  labs(x="Days between Samples", y="# of Samples",
       title="Histogram of # Days between Samples")
```

Among these samples, `r scales::percent(prop.table(table(filter(ent, DT<1.5)$CLASS))[['>104']])` were above the 104 threshold and `r scales::percent(1-prop.table(table(filter(ent, DT<1.5)$CLASS))[['<=70']])` were above the 70 threshold.

This table lists the fraction of samples collected within 1.5 days of previous sample by category.

```{r tbl-dt-1-day}
ent %>%
  filter(DT<1.5) %>%
  .$CLASS %>%
  table %>%
  prop.table %>%
  as.data.frame %>%
  kable(col.names=c('Range', 'Fraction'), digits=3)
```

But when did these daily consecutive samples occur? This figure shows the number of daily consecutive samples by month and year. There is an obvious outlier in August of 2005 with over 80 samples collected within 1.5 days of the previous sample.

```{r plot-dt-1-day-tile}
ent %>%
  filter(DT<1.5) %>%
  group_by(MONTH, YEAR) %>%
  summarise(N=n()) %>%
  ggplot(aes(factor(YEAR), factor(MONTH), fill=N)) + 
  geom_tile() +
  scale_fill_gradientn('# Samples', colours=rev(scales::brewer_pal(type = "seq", palette = 'Spectral')(9))) +
  labs(x="Year", y="Month",
       title="Number of Consecutive Daily Samples by Month and Year")
```

In summer of 2005, five stations at Goose Rocks were apparently sampled daily during weekdays, perhaps as part of a special intensive sampling program.

```{r plot-dt-goose-rocks, fig.width=10}
ent %>%
  filter((DT<1.5 | lead(DT)<1.5), YEAR==2005, MONTH %in% c(7, 8, 9),
         SITE_NAME %in% c("GR-1", "GR-2", "GR-3", "GR-4", "GR-5")) %>%
  ggplot(aes(SAMPLE_DATETIME, CONCENTRATION)) +
  geom_point() +
  facet_wrap(~SITE_NAME) +
  labs(x="Sample Date", y="ENT (MPN/100mL)", title="Daily Sampling at Goose Rocks in July-September 2005")
```

Using these daily samples, we can also look at the transition probabilities between 'clean' and 'dirty' days. For example, if a given sample is below the threshold (Clean), what is the chance that a sample collected on the following day is above the threshold (Dirty)?

```{r ent-day}
ent.day <- ent %>%
  group_by(SITE_NAME) %>%
  mutate(NEXT_DT=lead(DT),
         NEXT_CONCENTRATION=lead(CONCENTRATION),
         NEXT_GT_70=lead(GT_70),
         NEXT_GT_104=lead(GT_104),
         STATUS=ifelse(GT_104, 'D', 'C'),
         NEXT_STATUS=lead(STATUS),
         COMBINED_STATUS=paste0(STATUS, NEXT_STATUS)) %>%
  filter(NEXT_DT<1.5)
```

This figure shows the relationship between concentrations measured on consecutive days. The x-value is the concentration on the first day, the y-value is the concentration on the following day. The black line is a linear regression, which shows no strong relationship between concentrations on consecutive days. Note this includes all sites.

```{r plot-dt-1-day-scatter}
ent.day %>%
  ggplot(aes(CONCENTRATION, NEXT_CONCENTRATION)) +
  geom_point(aes(color=COMBINED_STATUS)) +
  geom_smooth(method='lm', se=FALSE, color='black') +
  log_x +
  log_y +
  # geom_hline(aes(yintercept=70, color=LABEL), color='deepskyblue', linetype='dashed') +
  geom_hline(aes(yintercept=104, color=LABEL), color='orangered', linetype='dashed') +
  # geom_vline(aes(xintercept=70, color=LABEL), color='deepskyblue', linetype='dashed') +
  geom_vline(aes(xintercept=104, color=LABEL), color='orangered', linetype='dashed') +
  scale_color_manual('',
                     values=c('CC'='grey50', 'CD'='deepskyblue', 'DC'='chartreuse3', 'DD'='orangered'),
                     labels=c('CC'='Clean -> Clean', 'CD'='Clean -> Dirty',
                              'DC'='Dirty -> Clean', 'DD'='Dirty -> Dirty')) +
  labs(x="ENT (MPN/100mL) on First Day", y="ENT (MPN/100mL) on Following Day",
       title="Relationship between Concentrations on Consecutive Days") +
  theme(panel.grid.minor=element_blank())
```

```{r ent-day-tbl}
ent.day.tbl <-
  table(plyr::revalue(ent.day$STATUS, c(C='Clean', D='Dirty')),
        plyr::revalue(ent.day$NEXT_STATUS, c(C='Clean', D='Dirty'))) %>%
  prop.table(margin=1)
```

This table lists the transition probabilities between Clean and Dirty over two consecutive days using the 104 threshold. The rows indicate the condition on the first day, the columns indicate the condition on the second day. The values are the probabilities of going from the row condition to the column condition (thus the sum of each row is 1). For example, if the first day was Dirty, then there is a `r scales::percent(ent.day.tbl['Dirty', 'Clean'])` chance of the next day being Clean and a `r scales::percent(ent.day.tbl['Dirty', 'Dirty'])` chance of the next day being Dirty.

```{r tbl-day-trans-prob}
ent.day.tbl %>%
  kable(digits=3)
```







```{r, eval=FALSE}
filter(ent, SITE_NAME %in% c("WIL-02", "EEB-01")) %>%
  group_by(SITE_NAME) %>%
  mutate(NEXT_DT=lead(DT)) %>%
  ggplot(aes(factor(YEAR), NEXT_DT)) +
  geom_boxplot() +
  ylim(0, 7) +
  facet_grid(SITE_NAME~GT_104)
```

```{r, eval=FALSE}
ent %>%
  filter(!(SITE_NAME %in% c("WIL-02", "EEB-01"))) %>%
  group_by(SITE_NAME) %>%
  mutate(NEXT_DT=lead(DT)) %>%
  ggplot(aes(factor(YEAR), NEXT_DT)) +
  geom_boxplot() +
  ylim(0, 6)
```

```{r, eval=FALSE}
ent %>%
  # filter(!(SITE_NAME %in% c("WIL-02", "EEB-01"))) %>%
  group_by(SITE_NAME) %>%
  mutate(NEXT_DT=round(lead(DT))) %>%
  filter(NEXT_DT < 7) %>%
  group_by(YEAR, NEXT_DT) %>%
  summarise(N=n()) %>%
  ggplot(aes(factor(YEAR), N, fill=factor(NEXT_DT))) +
  geom_bar(stat='identity', position='stack')

```

## Potential Resamples

When a sample exceeds the current 104 threshold, then a resample is supposed to be taken shortly after to determine when it is safe to open the beach. 

This section excludes `EEB-01` and `WIL-02` which Meagan identified as having routine sampling at 2 or 3 times per week.

This figure shows the number of samples per year that were collected within 6.5 days of the previous sample (and at the same site). The bars are split by the range of concentrations on the previous day.

```{r}
ent %>%
  filter(!(SITE_NAME %in% c("WIL-02", "EEB-01"))) %>%
  group_by(SITE_NAME) %>%
  mutate(PREV_CONCENTRATION=lag(CONCENTRATION),
         PREV_CLASS=lag(CLASS)) %>%
  filter(DT <= 6.5) %>%
  group_by(YEAR, PREV_CLASS) %>%
  summarise(N=n()) %>%
  ungroup %>%
  mutate(PREV_CLASS=ordered(PREV_CLASS, levels=rev(levels(PREV_CLASS)))) %>%
  ggplot(aes(factor(YEAR), N, fill=PREV_CLASS)) +
  geom_bar(stat='identity') +
  scale_class_fill +
  labs(x="Year", y="# of Samples")
```

This figure shows the fraction of samples collected in each year that were in each concentration range. 

Interestingly, the fraction of samples less than 104 decreased over time. In 2013 and 2014, about 25% of the samples that had another sample collected within 6.5 days despite being less than 104 MPN/100mL (and thus would not have triggered a resample). This suggests there other reasons why samples might be collected more than weekly.

```{r}
ent %>%
  filter(!(SITE_NAME %in% c("WIL-02", "EEB-01"))) %>%
  group_by(SITE_NAME) %>%
  mutate(PREV_CONCENTRATION=lag(CONCENTRATION),
         PREV_CLASS=lag(CLASS)) %>%
  filter(DT <= 6.5) %>%
  group_by(YEAR, PREV_CLASS) %>%
  summarise(N=n()) %>%
  ungroup %>%
  mutate(PREV_CLASS=ordered(PREV_CLASS, levels=rev(levels(PREV_CLASS)))) %>%
  ggplot(aes(factor(YEAR), N, fill=PREV_CLASS)) +
  geom_bar(stat='identity', position='fill') +
  scale_class_fill +
  scale_y_continuous(labels=scales::percent) +
  labs(x="Year", y="% of Samples",
       title="% of Samples by Concentration Range and Year\nOnly Including Samples where Next Sample is within 6.5 Days")

```

This is the same figure but using only samples where another sample was collected within 3.5 days. In 2013 and 2014, a relatively small fraction (<5%) were below the 104 threshold, which suggests that these were primarily re-samples. However, in 2003-2005, more than 50% of the samples were less than 104.

```{r}
ent %>%
  filter(!(SITE_NAME %in% c("WIL-02", "EEB-01"))) %>%
  group_by(SITE_NAME) %>%
  mutate(PREV_CONCENTRATION=lag(CONCENTRATION),
         PREV_CLASS=lag(CLASS)) %>%
  filter(DT <= 3.5) %>%
  group_by(YEAR, PREV_CLASS) %>%
  summarise(N=n()) %>%
  ungroup %>%
  mutate(PREV_CLASS=ordered(PREV_CLASS, levels=rev(levels(PREV_CLASS)))) %>%
  ggplot(aes(factor(YEAR), N, fill=PREV_CLASS)) +
  geom_bar(stat='identity', position='fill') +
  scale_class_fill +
  scale_y_continuous(labels=scales::percent) +
  labs(x="Year", y="% of Samples",
       title="% of Samples by Concentration Range and Year\nOnly Including Samples where Next Sample is within 3.5 Days")

```

This figure shows how the distribution of samples in each category changes depending on the number of days until the next sample. There is a large shift from primarily samples exceeding 104 to primarily samples <= 70 between 4.5-7.5 days. This suggests that resamples are primarily collected within 4.5 days.

```{r}
compute <- function(n) {
  ent %>%
    filter(!(SITE_NAME %in% c("WIL-02", "EEB-01")), YEAR!=2005) %>%
    group_by(SITE_NAME) %>%
    mutate(PREV_CONCENTRATION=lag(CONCENTRATION),
           PREV_CLASS=lag(CLASS)) %>%
    filter(DT <= n) %>%
    group_by(PREV_CLASS) %>%
    summarise(N=n()) %>%
    ungroup %>%
    mutate(N_DT=n)
}
lapply(seq(1.5, 13, 0.5), compute) %>%
  rbind_all %>%
  group_by(N_DT) %>%
  mutate(N_TOTAL=sum(N)) %>%
  ungroup %>%
  mutate(VALUE=N/N_TOTAL) %>%
  ggplot(aes(N_DT, VALUE, color=PREV_CLASS)) +
  geom_point() +
  geom_line() +
  scale_class_color +
  scale_x_continuous(breaks=seq(0, 20, 1), limits=c(0, NA)) +
  scale_y_continuous(labels=scales::percent, limits=c(0, 1)) +
  labs(x="Days until Next Sample", y="Mean % of Samples")
```

```{r, eval=FALSE}
ent %>%
  filter(!(SITE_NAME %in% c("WIL-02", "EEB-01"))) %>%
  group_by(SITE_NAME) %>%
  mutate(PREV_CONCENTRATION=lag(CONCENTRATION),
         PREV_CLASS=lag(CLASS)) %>%
  filter(DT <= 6.5, PREV_CLASS %in% c("<=70", "70-104")) %>%
  select(TOWN, BEACH_NAME, SITE_NAME) %>%
  unique
```


```{r, eval=FALSE}
ent %>%
  filter(!(SITE_NAME %in% c("WIL-02", "EEB-01"))) %>%
  group_by(SITE_NAME) %>%
  mutate(PREV_CONCENTRATION=lag(CONCENTRATION),
         PREV_CLASS=lag(CLASS)) %>%
  filter(DT <= 6.5) %>%
  ggplot(aes(PREV_CONCENTRATION, CONCENTRATION)) +
  geom_point() +
  log_y + 
  log_x
```


```{r}
opts_chunk$set(eval=FALSE)
```

```{r}
group_by(ent, SAMPLE_POINT_NAME) %>%
  summarise(N=n(),
            MIN=min(DT, na.rm=TRUE),
            MED=median(DT, na.rm=TRUE),
            MAX=max(DT, na.rm=TRUE)) %>%
  arrange(MED) %>%
  as.data.frame
```

```{r}
filter(ent, SAMPLE_POINT_NAME=="MDI-03") %>%
  filter(DT<50) %>%
  ggplot(aes(yday(SAMPLE_DATE), DT, color=GT_104)) +
  geom_point() +
  ylim(0, NA) +
  scale_color_manual('> 104', values=c("TRUE"='red', 'FALSE'='grey50')) +
  facet_wrap(~YEAR, scales='free_x')
```


```{r}
ent %>%
  # filter(SAMPLE_POINT_NAME=="BID-01") %>%
  mutate(WEEK=week(SAMPLE_DATE)) %>%
  group_by(YEAR, WEEK) %>%
  summarise(N=n(),
            N_SITE=length(unique(SAMPLE_POINT_NAME)),
            FRAC=N/N_SITE) %>%
  ungroup %>%
  ggplot(aes(factor(YEAR), factor(WEEK), fill=FRAC)) +
  geom_tile() +
  labs(x='Year', y='Week of Year') +
  scale_fill_gradientn('# Sample\nper Site', colours=rev(scales::brewer_pal(type = "seq", palette = 'Spectral')(9)))
```

```{r}
ent %>%
  group_by(YEAR, MONTH) %>%
  summarise(N=n(),
            N_SITE=length(unique(SAMPLE_POINT_NAME)),
            FRAC=N/N_SITE) %>%
  ungroup %>%
  ggplot(aes(factor(YEAR), factor(MONTH), fill=FRAC)) +
  geom_tile() +
  labs(x='Year', y='Month of Year') +
  scale_fill_gradientn('# Sample\nper Site', colours=rev(scales::brewer_pal(type = "seq", palette = 'Spectral')(9)))
```



```{r}
ent %>%
  group_by(YEAR) %>%
  summarise(N=n(),
            N_SITE=length(unique(SAMPLE_POINT_NAME)),
            FRAC=N/N_SITE) %>%
  ungroup %>%
  ggplot(aes(factor(YEAR), N_SITE, fill=FRAC)) +
  geom_bar(stat='identity') +
  labs(x='Year', y='# Sites') +
  scale_fill_gradientn('# Sample\nper Site', colours=rev(scales::brewer_pal(type = "seq", palette = 'Spectral')(9)))
```


```{r}
ent %>%
  mutate(WEEK=week(SAMPLE_DATE)) %>%
  group_by(SAMPLE_POINT_NAME, YEAR, WEEK) %>%
  summarise(N=n()) %>%
  ungroup %>%
  group_by(SAMPLE_POINT_NAME) %>%
  summarise(MIN=min(N),
            MAX=max(N),
            MEAN=mean(N),
            MEDIAN=median(N),
            STDEV=sd(N),
            N=sum(N)) %>%
  arrange(desc(MEDIAN)) %>%
  as.data.frame
```

```{r}
ent %>%
  mutate(WEEK=week(SAMPLE_DATE)) %>%
  group_by(SAMPLE_POINT_NAME, YEAR, MONTH) %>%
  summarise(N=n()) %>%
  ungroup %>%
  group_by(SAMPLE_POINT_NAME) %>%
  summarise(MIN=min(N),
            MAX=max(N),
            MEAN=mean(N),
            MEDIAN=median(N),
            STDEV=sd(N),
            N=sum(N)) %>%
  arrange(desc(MAX)) %>%
  as.data.frame
```



```{r, eval=FALSE}
# What fraction of samples that are within 5 days of a previous exceedence also exceed 104
ent <- group_by(ent, SAMPLE_POINT_NAME) %>%
  mutate(PREV_CLASS = ifelse(lag(GT_104), 'D', 'C'),
         CURR_CLASS = ifelse(GT_104, 'D', 'C'),
         CLASS = ifelse(is.na(PREV_CLASS), NA, paste0(PREV_CLASS, CURR_CLASS))) %>%
  mutate(CLASS=ordered(CLASS, levels=c('CC', 'CD', 'DC', 'DD')))

ent %>%
  filter(!is.na(CLASS)) %>%
  filter(DT < 5) %>%
  group_by(CLASS) %>%
  summarise(N=n())



ent %>%
  filter(!is.na(CLASS)) %>%
  filter(DT < 7) %>%
  group_by(SAMPLE_POINT_NAME, CLASS) %>%
  summarise(N=n()) %>%
  mutate(N_SITE=sum(N)) %>%
  ungroup %>%
  filter(N_SITE > 10) %>%
  spread(CLASS, N, fill=0) %>%
  arrange(desc(DD/N_SITE)) %>%
  mutate(SAMPLE_POINT_NAME=ordered(SAMPLE_POINT_NAME, levels=SAMPLE_POINT_NAME)) %>%
  gather(CLASS, N, -SAMPLE_POINT_NAME, -N_SITE) %>%
  ggplot(aes(SAMPLE_POINT_NAME, N, fill=CLASS)) +
  geom_bar(stat='identity', position='fill') +
  theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))


  filter(CLASS %in% c('DC', 'DD')) %>%
  group_by(SAMPLE_POINT_NAME, CLASS) %>%
  summarise(N=n()) %>%
  mutate(N_SITE=sum(N),
         FRAC=N/N_SITE) %>%
  select(-N) %>%
  ungroup %>%
  spread(CLASS, FRAC, fill=0) %>%
  arrange(desc(DD)) %>%
  mutate(SAMPLE_POINT_NAME=ordered(SAMPLE_POINT_NAME, levels=SAMPLE_POINT_NAME)) %>%
  gather(CLASS, FRAC, -SAMPLE_POINT_NAME, -N_SITE) %>%
  filter(N_SITE > 4) %>%
  ggplot(aes(SAMPLE_POINT_NAME, FRAC, fill=CLASS)) +
  geom_bar(stat='identity', position='stack') +
  theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))
```



```{r}
# overall distribution
ggplot(ent, aes(log10(CONCENTRATION))) + geom_histogram(binwidth=0.2) + geom_vline(xint=log10(70)) + geom_vline(xint=log10(104))
```


```{r}
# what is fraction of samples between 70 and 104? 6%
ungroup(ent) %>%
  mutate(CLASS=CONCENTRATION >= 70 & CONCENTRATION <= 104) %>%
  group_by(CLASS) %>%
  tally
```




```{r}
# if sample > 70, what is prob its also > 104?  ~60%
ungroup(ent) %>%
  filter(CONCENTRATION >= 70) %>%
  mutate(GT_104 = (CONCENTRATION > 104)) %>%
  group_by(GT_104) %>%
  tally
```

